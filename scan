#!/usr/bin/env python
import requests, re, json, base64, html, random, sys, time, copy, os, threading, argparse
from bs4 import BeautifulSoup
from pwn import log
import jsbeautifier






regex_str = r"""
  (?:"|')                               # Start newline delimiter
  (
    ((?:[a-zA-Z]{1,10}://|//)           # Match a scheme [a-Z]*1-10 or //
    [^"'/]{1,}\.                        # Match a domainname (any character + dot)
    [a-zA-Z]{2,}[^"']{0,})              # The domainextension and/or path
    |
    ((?:/|\.\./|\./)                    # Start with /,../,./
    [^"'><,;| *()(%%$^/\\\[\]]          # Next character can't be...
    [^"'><,;|()]{1,})                   # Rest of the characters can't be
    |
    ([a-zA-Z0-9_\-/]{1,}/               # Relative endpoint with /
    [a-zA-Z0-9_\-/]{1,}                 # Resource name
    \.(?:[a-zA-Z]{1,4}|action)          # Rest + extension (length 1-4 or action)
    (?:[\?|#][^"|']{0,}|))              # ? or # mark with parameters
    |
    ([a-zA-Z0-9_\-/]{1,}/               # REST API (no extension) with /
    [a-zA-Z0-9_\-/]{3,}                 # Proper REST endpoints usually have 3+ chars
    (?:[\?|#][^"|']{0,}|))              # ? or # mark with parameters
    |
    ([a-zA-Z0-9_\-]{1,}                 # filename
    \.(?:php|asp|aspx|jsp|json|
         action|html|js|txt|xml)        # . + extension
    (?:[\?|#][^"|']{0,}|))              # ? or # mark with parameters
  )
  (?:"|')                               # End newline delimiter
"""



def user_agent():
    user_agent_list = [
            'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36 OPR/85.0.4341.71',
            'Mozilla/5.0 (Windows; U; Windows NT 5.2; es-VE) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.70 Safari/537.36 UCBrowser/13.4.0.1306',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.5112.101 Safari/537.36 Edg/104.0.1293.70',
            'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.127 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4476.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.5195.79 Safari/537.36 OPR/91.0.4516.78',
            'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.72 Safari/537.36 Edg/90.0.818.42',
            
    ]
    user_agent = random.choice(user_agent_list)
    return user_agent
###################################################################################################


def scrap(content, js=False):
    
    #If the file contains javascript, beautify it.    
    if js:
        if len(content) > 1000000:
            content = content.replace(";",";\r\n").replace(",",",\r\n")
        else:
            #Beautify 
            content = jsbeautifier.beautify(content)
            
  
        
    #Find urls on the file
    regex = re.compile(regex_str, re.VERBOSE)
    for m in re.finditer(regex, content):
        if m.group(1) not in links["full_urls"] and m.group(1) is not None:
            links["full_urls"].append(m.group(1))
        if m.group(2) not in links["path_trv"] and m.group(2) is not None:
            links["path_trv"].append(m.group(2))
        if m.group(3) not in links["endpoint"] and m.group(3) is not None:
            links["endpoint"].append(m.group(3))
        if m.group(4) not in links["relative_with_ext"] and m.group(4) is not None:
            links["relative_with_ext"].append(m.group(4))

    return links

#########################################################################################























links = {
    "full_urls": [],
    "path_trv": [],
    "endpoint": [],
    "relative_with_ext": [], 
}
if os.path.isfile("data.json"):
    with open("data.json", "r") as file:
        links = json.load(file)
        


#Check args
parser = argparse.ArgumentParser()
parser.add_argument("-t", "--target", type=str, help="Url to scan", required=True)
parser.add_argument("-c", "--cookies", nargs='+', type=str, help="Set the cookies using this format cookie=value", required=False, default=False)
args = parser.parse_args()

url = args.target

cookies = {}
if args.cookies:
    for cookie in args.cookies:
        cookie = cookie.split("=")
        cookies[cookie[0]] = cookie[1]
#####################

        
          
        
     



if __name__ == "__main__":
     
    content = requests.get(url, cookies=cookies, headers={"User-Agent":user_agent()}).content
    
    
    
  